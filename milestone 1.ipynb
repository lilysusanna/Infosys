{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hk9XDIE-bWS",
        "outputId": "8031689e-5ea4-498b-a6b7-057d89c3d9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q vosk jiwer\n",
        "!apt-get install -y ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# pick first uploaded wav/mp3 file\n",
        "AUDIO_FILE = [f for f in uploaded.keys() if f.endswith(('.wav','.mp3'))][0]\n",
        "print(\"Using audio file:\", AUDIO_FILE)\n"
      ],
      "metadata": {
        "id": "eZ263DNj-ySE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "52b8e566-5633-4b14-a875-294a2bc24e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-baa3f274-ac45-4f12-944d-9877ca23e014\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-baa3f274-ac45-4f12-944d-9877ca23e014\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new_audio.wav to new_audio.wav\n",
            "Using audio file: new_audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# transcribe audio\n",
        "whisper_result = model.transcribe(AUDIO_FILE)\n",
        "\n",
        "# show transcription\n",
        "print(\"Whisper Transcript:\\n\")\n",
        "print(whisper_result[\"text\"])\n",
        "\n",
        "# save transcript\n",
        "with open(\"whisper_transcript.txt\", \"w\") as f:\n",
        "    f.write(whisper_result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6iv1ZeRAT5L",
        "outputId": "b9d789c9-26d3-4605-ab8e-c0f2d7f70e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 36.6MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper Transcript:\n",
            "\n",
            " I wonder how many meetings is talking about the stuff with the meetings. Yeah, yeah, yeah, yeah. Look at all these stuff, right? Yeah. Okay. Okay. So, what do we need to talk about? Should we just go around and everyone says what they've been doing? Is it not about anything? Not at all. Why, I'm sorry. Yeah. Okay. Sounds like you've done something. That's not it. Well, I've got a browser now, which, whoops, all right, go. Good stuff. Mm-hmm. Well, I dropped mine as well. Good at this. This was something good started. Okay. So, yeah, we've got a browser, which comes up automatically. Which comes up automatically with the transcription box and the topics. And then when you go on the menu, you can select the summarisation box, which pops up, and an audio player. Right. And I think the search works as well. So, pop up a search. It loads up just the background window, so empty. And so, when you start, you have to either open a particular observation or do a search and open it through that. That like sense? The transcription box has got a summarised button, which doesn't do anything yet. Now, I wonder how we want to do, you know, we want to pop up one door with the speaker character evaluation. Either we could do that, you know, when does the pop up come? Either we can, when you click on the ID, any sort of ID in the transcription box, or we can put an extra button, extra few buttons, next to the summarised button, so that you actually in the transcription box, but so that you click on the button and then it opens and so on. That's speaker characterisation. The problem is the left click is already used because it highlights that part of speech or whatever that. The left click. The left click highlights it. So that will be good. I don't know what happens when you double click, actually. Without be a bit annoying if you have left click for one thing and double click for something. I think so, yeah, when you left click it, you can for example set the marker there so that the audio goes from there, I think. So we can't put it on left click. We could put it on the right click. We could, for example, have a little menu that pops up. Yeah, it might be quite a good one. So right click on it menu, you know, and you can click on the speaker characterisation of the pop zoom. What else can we have in there? Menu. That's a good point. I don't know. I don't know. I don't know. I don't know why we just have a right click on the other. Yeah, yeah, but I don't know about you, but usually in Windows right click. Is it, do anything? It opens the menu. Yeah, that's what it will be. Yeah, I said we might a bit, a bit, a bit weird, just start bringing up stuff. Yeah, to just answer the same sort of idiom throughout. Yeah. Yeah, or just, you know, or just a button. I guess a button makes a bit more sense because otherwise you don't really know that, oh, what if I right click now? What happens then? Well, no, it's not official. Yeah, the menu pop up that. Well, oh, yeah, it's more obvious, isn't it? It's more of an idea. It's got a button. Yeah, that's true. Yeah, it's more intuitive. But, well, we have more things in the future than we have in the buttons. We'll work some menus. Maybe. Maybe. More flexible. Yeah, yeah. Yeah, yeah. Well, I guess in meeting browser 1.1, you can have a menu instead of a box. Right. This one's a bit weird. But actually, what we could do is, in that menu as well, we could have an option that pops up a window with all the, all the meetings that that user has been in, like a search for that user. Is that going to be useful or too much? I guess so. So what did you, part of the menu that comes down is says, give me all your meetings. Yeah. So when you right click on it, one option will be, give me all your meetings, characterise a speaker. Yeah. Or is that too much, I mean? I guess so. I mean, it's more like part of the browsing sort of thing. More than the speaker character translation, as Steve mentioned. Yeah. So we know how to. Yeah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, wave, json\n",
        "from vosk import Model, KaldiRecognizer\n",
        "\n",
        "# download a small English model if not already present\n",
        "if not os.path.exists(\"vosk-model-small-en-us-0.15\"):\n",
        "    !wget -q https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "    !unzip -q vosk-model-small-en-us-0.15.zip\n",
        "\n",
        "# load model\n",
        "vosk_model = Model(\"vosk-model-small-en-us-0.15\")\n",
        "\n",
        "# open audio file\n",
        "wf = wave.open(AUDIO_FILE, \"rb\")\n",
        "rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "rec.SetWords(True)\n",
        "\n",
        "# run recognition\n",
        "vosk_text = \"\"\n",
        "while True:\n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        result = json.loads(rec.Result())\n",
        "        vosk_text += \" \" + result.get(\"text\", \"\")\n",
        "final_result = json.loads(rec.FinalResult())\n",
        "vosk_text += \" \" + final_result.get(\"text\", \"\")\n",
        "\n",
        "# show transcript\n",
        "print(\"Vosk Transcript:\\n\")\n",
        "print(vosk_text)\n",
        "\n",
        "# save transcript\n",
        "with open(\"vosk_transcript.txt\", \"w\") as f:\n",
        "    f.write(vosk_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J93mwcVZAzAd",
        "outputId": "17516cb3-f748-4bf0-e758-8dfd1822afc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vosk Transcript:\n",
            "\n",
            " when winter comes to the meetings as talking about the stuff of the meetings yeah nevertheless the here get certificate right so we really need to talk about the bodies are we just go around and everyone says what they what they've been doing that without anything live say yeah sounds like you've done i could do that i've got a browser now which whoops no good stuff when of mine as well mississippi given this this wasn't a good start okay sorry yeah say yeah we've got browser read which comes up automatically with or transcription box and the topics and then when you go on the menu you can select some ization box which pops up and an audio player one am and as i think search works as well say pop up a search and loads up just the background when nice empty end so when you start you have to either open open up seek the observation or do such an open it through that that make sense em the transcription boss has got a summarize book button which doesn't do anything it i am now i wonder how we wanna do you know we want to pop up window with the a characterization i didn't either we could do that in a when a pop up come either we can when you click on the the id any sort of id in the transcription box or we can put an extra been x or few buttons nicer summarize button so that you are she in the transcription books but saw you click on a button and then the absence why the not speak a characterization is the problem is the the left click is already used because it highlights that am that pass speech or whatever that more he's attacking the left over the look like highlights it was kill that they're looking for i don't know haven't when you don't like actually but be bit and or if you have left click for one thing and double click was a new i am i think so yeah when you left like it you can for example set set the mark of as that then the order goes from laughing i'm sorry can't put it on left think we could put it on the right click wicked for example have little many that pops up there are recall give us was i right click on it menu you know and you can click on speaker characterization of pups wonder what else could we have in the when you must a good point hannah realizes his and right your hotel am i don't know about uber a usually in windows right click is it would do anything is a a opens a menu menu union leaders way to be those a yeah the sit with my baby were before he artists double know stuff here digital censoring the same sort of it i'm thrilled yeah yeah them or just in our orders the button i guess a bet on that i'm makes a bit more sense cause otherwise you don't really know that oh what if i have the right click know what happens them is well known or it a visual yeah the menus hello that well oh yeah is more obvious his name already a group isn't it is go back and good yeah yeah sir yeah more into his limousine is a great well we'll get we'll have more things are have you turn around to about new buttons have your were some and your main thing is mary more flexible hours yeah we're in a a guess in in a meeting browser one point work and you can have a menu instead of a perfect right thing is i will be timid actually what we do is on in that many as well we could have an option that pops up a window with all the or the meetings that that user has been in like a search for that user give that gonna be useful too much though i guess oh so why did part the boot the many that comes down his says give you a meetings as yeah so when you're right click on it one one option will make he only meetings characterize the speaker yet or that too much and when the guess a semi do it's more like part of the browsing sort of thing while then they speak it hurts it the recession as nasty mention know the really know how dare hear him\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer\n",
        "\n",
        "whisper_text = whisper_result[\"text\"].strip()\n",
        "vosk_text = vosk_text.strip()\n",
        "\n",
        "# use Whisper transcript as reference, compare Vosk\n",
        "wer_whisper = wer(whisper_text, whisper_text)  # always 0\n",
        "wer_vosk = wer(whisper_text, vosk_t9ext)\n",
        "\n",
        "print(\"Whisper WER:\", round(wer_whisper, 2))\n",
        "print(\"Vosk WER   :\", round(wer_vosk, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30DiDZgmBQWB",
        "outputId": "36cd7d8b-42ab-4c06-fdbe-e3e255005ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper WER: 0.0\n",
            "Vosk WER   : 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"whisper_transcript.txt\")\n",
        "files.download(\"vosk_transcript.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WCtokWSvBVG8",
        "outputId": "eca20042-efb8-4c23-f9c7-927e74c2f273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1e835da2-23b6-4c0b-87b8-387783c42aae\", \"whisper_transcript.txt\", 4008)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e74d2584-043a-486f-899c-8326540ad500\", \"vosk_transcript.txt\", 3798)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}