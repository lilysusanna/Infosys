{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1WaC30BG_Sv",
        "outputId": "c740eaa0-2add-4ec3-c8d5-33aaa031f757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'srt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'srt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Upgrade pip and install ffmpeg\n",
        "!pip install --upgrade pip\n",
        "!apt-get install ffmpeg -y\n",
        "\n",
        "# Install torch and Whisper\n",
        "!pip install torch --quiet\n",
        "!pip install git+https://github.com/openai/whisper.git --quiet\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install vosk streamlit pyngrok jiwer soundfile groq --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r9wpkHcHOv2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import whisper\n",
        "import soundfile as sf\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from groq import Groq\n",
        "from jiwer import wer\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXvy_WUDLOPa"
      },
      "outputs": [],
      "source": [
        "# Set your Groq API key here\n",
        "# Replace \"gsk_your_actual_api_key_here\" with your actual key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11SRsJTFHcWw"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"meeting_pipeline\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0PfFA_bHeGY",
        "outputId": "0509e35d-09dd-4c9a-f8ea-bd15761afe6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 117MiB/s]\n"
          ]
        }
      ],
      "source": [
        "whisper_model = whisper.load_model(\"small\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYQDukPPHhkY"
      },
      "outputs": [],
      "source": [
        "# Download a small Vosk English model if not present\n",
        "if not os.path.exists(\"vosk-model-small-en-us-0.15\"):\n",
        "    !wget -q https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "    !unzip -q vosk-model-small-en-us-0.15.zip\n",
        "\n",
        "vosk_model = Model(\"vosk-model-small-en-us-0.15\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MjfT3Y0HtBk"
      },
      "outputs": [],
      "source": [
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# Summarization function using Groq 'compound' model\n",
        "def summarize_with_groq(text):\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"groq/compound\",  # Model your key has access to\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional meeting summarizer. Summarize the transcript clearly and concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Meeting Transcript:\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvavsRguHuf_"
      },
      "outputs": [],
      "source": [
        "# Whisper transcription\n",
        "def transcribe_audio(file_path):\n",
        "    result = whisper_model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Vosk diarization\n",
        "def diarize_audio(file_path):\n",
        "    import wave\n",
        "    wf = wave.open(file_path, \"rb\")\n",
        "    rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "    segments = []\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            res = json.loads(rec.Result())\n",
        "            if 'text' in res:\n",
        "                segments.append(res['text'])\n",
        "    final_res = json.loads(rec.FinalResult())\n",
        "    if 'text' in final_res:\n",
        "        segments.append(final_res['text'])\n",
        "    return segments\n",
        "\n",
        "# Summarization using Groq\n",
        "def summarize_text(text):\n",
        "    return summarize_with_groq(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPUHIYT2HxrZ"
      },
      "outputs": [],
      "source": [
        "app_code = \"\"\"\\\n",
        "import streamlit as st\n",
        "import whisper\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    whisper_model = whisper.load_model(\"small\")\n",
        "    vosk_model = Model(\"vosk-model-small-en-us-0.15\")\n",
        "    groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "    return whisper_model, vosk_model, groq_client\n",
        "\n",
        "whisper_model, vosk_model, groq_client = load_models()\n",
        "\n",
        "st.title(\"Meeting Transcription + Diarization + Summarization (GroqAI)\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a meeting .wav file\", type=[\"wav\"])\n",
        "\n",
        "def summarize_with_groq(client, text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"groq/compound\",  # Accessible model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional meeting summarizer. Summarize the transcript clearly and concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Meeting Transcript:\\\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    with open(\"temp.wav\", \"wb\") as f:\n",
        "        f.write(uploaded_file.read())\n",
        "\n",
        "    st.info(\"Transcribing...\")\n",
        "    transcription = whisper_model.transcribe(\"temp.wav\")[\"text\"]\n",
        "    st.success(\"Transcription complete!\")\n",
        "    st.text_area(\"Transcription\", transcription, height=200)\n",
        "\n",
        "    st.info(\"Performing diarization...\")\n",
        "    wf = wave.open(\"temp.wav\", \"rb\")\n",
        "    rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "    segments = []\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            res = json.loads(rec.Result())\n",
        "            if 'text' in res:\n",
        "                segments.append(res['text'])\n",
        "    final_res = json.loads(rec.FinalResult())\n",
        "    if 'text' in final_res:\n",
        "        segments.append(final_res['text'])\n",
        "    st.success(\"Diarization complete!\")\n",
        "    st.text_area(\"Diarized Transcript\", \"\\\\n\".join(segments), height=200)\n",
        "\n",
        "    st.info(\"Summarizing with GroqAI...\")\n",
        "    summary = summarize_with_groq(groq_client, transcription)\n",
        "    st.success(\"Summary complete!\")\n",
        "    st.text_area(\"Meeting Summary\", summary, height=150)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/meeting_pipeline/app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67eNnkOOHzvE"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsXcXCpAH1QV",
        "outputId": "6b2e4427-6dcf-468e-c798-dce3bebef998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your own ngrok auth token\n",
        "ngrok.set_auth_token(\"34N32YpgFHSFlldFEog5AKzrvjl_3juVrXhr5nmRG38PdJSta\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D3FVDofPHbT",
        "outputId": "004447ba-9e46-479b-dd28-64496e5e3b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: https://c1a9cb64dc6c.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Then start a new tunnel\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8FkJE-i97SF",
        "outputId": "d1151c92-5837-4d85-f41f-8ee19ed955bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/meeting_pipeline/app.py\n"
          ]
        }
      ],
      "source": [
        "!ls /content/meeting_pipeline/app.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc9Egv2t-DbJ"
      },
      "outputs": [],
      "source": [
        "!pkill -f streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlOrO7QZ-FQ4"
      },
      "outputs": [],
      "source": [
        "!nohup streamlit run /content/meeting_pipeline/app.py --server.port 8501 > /content/meeting_pipeline/streamlit.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khrNwq7p-HFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6e71c8-ce45-4faa-c469-bfbc90bb467e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-10-21T10:46:15+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "time.sleep(10)  # Wait 10 seconds for the server to initialize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzZfAb7l-KTe",
        "outputId": "c7b7f325-c7c4-4176-f481-fec6c6b6753d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.16.173.77:8501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tail -n 20 /content/meeting_pipeline/streamlit.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8gG79YR-N9O",
        "outputId": "b0dc0bb5-be1c-41a2-9292-38544fafb41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: https://a664418d787b.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any old tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start new tunnel on the port Streamlit is running\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}