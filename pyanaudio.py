# -*- coding: utf-8 -*-
"""PYANAUDIO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dMd2nYfam7BiqEBc4q_XrSuDHBdxoALz
"""

!pip install pyannote.audio==3.1.1
!pip install librosa pandas matplotlib jiwer
!pip install torch torchvision torchaudio

from huggingface_hub import notebook_login
notebook_login()

import numpy as np

# Temporary fix for libraries expecting np.NaN
if not hasattr(np, "NaN"):
    np.NaN = np.nan

from pyannote.audio import Pipeline
from pyannote.metrics.diarization import DiarizationErrorRate
from pyannote.core import Annotation, Segment

print("Patch applied. You can now use pyannote.audio without NumPy errors.")

import numpy as np
from packaging import version

# Check NumPy version
if version.parse(np.__version__) >= version.parse("2.0.0"):
    print(f"Warning: NumPy {np.__version__} detected. Some libraries may break.")
    # Temporary fix for libraries expecting np.NaN
    if not hasattr(np, "NaN"):
        np.NaN = np.nan
        print("Patched: Added np.NaN alias for compatibility.")
else:
    print(f"NumPy {np.__version__} is compatible. No patch needed.")

# Now safe to import pyannote
from pyannote.audio import Pipeline
from pyannote.metrics.diarization import DiarizationErrorRate
from pyannote.core import Annotation, Segment

print("Environment ready. You can use pyannote.audio now.")

from huggingface_hub import notebook_login
notebook_login()

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")

import os

AUDIO_FILE = "/content/EN2002a.wav"  # full path to your file

if not os.path.exists(AUDIO_FILE):
    raise FileNotFoundError(f"Audio file not found: {AUDIO_FILE}")

print("Found audio file:", AUDIO_FILE)

!pip install --upgrade huggingface_hub
from huggingface_hub import login
login()  # will prompt for your token securely

from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")

!pip install --upgrade --force-reinstall numpy==1.26.4
import numpy as np
print(np.__version__)  # should print 1.26.4

from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")

!nvidia-smi

!huggingface-cli logout

!pip install --upgrade huggingface_hub

from huggingface_hub import notebook_login
notebook_login()

import os
import torch
import torchaudio
import numpy as np
from pyannote.audio import Pipeline

# Load diarization pipeline
# Removed use_auth_token as notebook_login() is used for authentication
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")

# Make sure we run on GPU if available
pipeline.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))

# Path to your single audio file
audio_file = "/content/EN2002a.wav"

# Output folder
os.makedirs("/content/diarization_outputs", exist_ok=True)

# --- Split audio into 5-minute chunks to speed up processing ---
waveform, sample_rate = torchaudio.load(audio_file)
chunk_duration = 5 * 60 * sample_rate  # 5 minutes
num_chunks = int(np.ceil(waveform.shape[1] / chunk_duration))

print(f"Processing {num_chunks} chunks using {'GPU' if torch.cuda.is_available() else 'CPU'}...")

for i in range(num_chunks):
    start = i * chunk_duration
    end = min((i + 1) * chunk_duration, waveform.shape[1])
    chunk_waveform = waveform[:, start:end]
    chunk_path = f"/content/temp_chunk_{i}.wav"
    torchaudio.save(chunk_path, chunk_waveform, sample_rate)

    print(f"Running diarization on chunk {i+1}/{num_chunks}...")
    diarization = pipeline(chunk_path)
    rttm_path = f"/content/diarization_outputs/EN2002a_chunk_{i}.rttm"
    with open(rttm_path, "w") as f:
        diarization.write_rttm(f)

    os.remove(chunk_path)  # clean up temporary chunk

print("âœ… Diarization completed for all chunks!")

def segments_to_rttm(segments, output_path, file_id):
    with open(output_path, "w") as rttm:
        for seg in segments:
            start_time = seg["start"]
            duration = seg["end"] - seg["start"]
            speaker = seg["speaker"]
            rttm.write(
                f"SPEAKER {file_id} 1 {start_time:.3f} {duration:.3f} <NA> <NA> {speaker} <NA> <NA>\n"
            )
    print(f"RTTM saved: {output_path}")

import glob

output_file = "/content/diarization_full.rttm"
with open(output_file, "w") as outfile:
    for fname in sorted(glob.glob("/content/EN2002a_chunk_*.rttm")):
        with open(fname) as infile:
            outfile.write(infile.read())

print(f"Merged RTTM saved at {output_file}")

pip install pyannote.metrics

!head -n 5 /content/diarization_full.rttm
!head -n 5 /content/transcript_rttms/whisper_EN2002a.rttm
!head -n 5 /content/transcript_rttms/vosk_EN2002a.rttm

import glob

output_file = "/content/diarization_full.rttm"
with open(output_file, "w") as outfile:
    for fname in sorted(glob.glob("/content/EN2002a_chunk_*.rttm")):
        with open(fname) as infile:
            for line in infile:
                # Replace the chunk name with EN2002a so it's consistent
                outfile.write(line.replace(fname.split('/')[-1].replace('.rttm',''), 'EN2002a'))

print(f"Merged RTTM saved at {output_file}")

# Example for Whisper:
with open("/content/whisper_EN2002a.rttm", "r") as infile:
    data = infile.read().replace("whisper_EN2002a", "EN2002a")
with open("/content/whisper_EN2002a.rttm", "w") as outfile:
    outfile.write(data)

# Example for Vosk:
with open("/content/vosk_EN2002a.rttm", "r") as infile:
    data = infile.read().replace("vosk_EN2002a", "EN2002a")
with open("/content/vosk_EN2002a.rttm", "w") as outfile:
    outfile.write(data)

from pyannote.metrics.diarization import DiarizationErrorRate
from pyannote.core import Annotation, Segment
from pyannote.database.util import load_rttm
import glob

# Load RTTMs
diarization_rttms = load_rttm("/content/diarization_full.rttm")
whisper_rttms = load_rttm("/content/whisper_EN2002a.rttm")
vosk_rttms = load_rttm("/content/vosk_EN2002a.rttm")

# Consolidate annotations for 'EN2002a'
diarization = Annotation()
for file_id, annotation in diarization_rttms.items():
    if file_id == "EN2002a":
        diarization = annotation
        break
    # Fallback to use the first file_id found if EN2002a is not present
    if not diarization and file_id:
        diarization = annotation
        print(f"Warning: 'EN2002a' not found in diarization RTTM. Using '{file_id}' instead.")
        break


whisper = Annotation()
for file_id, annotation in whisper_rttms.items():
    if file_id == "EN2002a":
        whisper = annotation
        break
    # Fallback to use the first file_id found if EN2002a is not present
    if not whisper and file_id:
        whisper = annotation
        print(f"Warning: 'EN2002a' not found in whisper RTTM. Using '{file_id}' instead.")
        break

vosk = Annotation()
for file_id, annotation in vosk_rttms.items():
    if file_id == "EN2002a":
        vosk = annotation
        break
    # Fallback to use the first file_id found if EN2002a is not present
    if not vosk and file_id:
        vosk = annotation
        print(f"Warning: 'EN2002a' not found in vosk RTTM. Using '{file_id}' instead.")
        break


# Calculate DER
metric = DiarizationErrorRate()

# Check if annotations were loaded before calculating DER
if diarization and whisper:
    der_whisper = metric(diarization, whisper)
    print(f"DER vs Whisper: {der_whisper*100:.2f}%")
else:
    print("Could not load diarization or whisper annotations. Cannot calculate DER vs Whisper.")

if diarization and vosk:
    der_vosk = metric(diarization, vosk)
    print(f"DER vs Vosk: {der_vosk*100:.2f}%")
else:
     print("Could not load diarization or vosk annotations. Cannot calculate DER vs Vosk.")

import glob

output_file = "/content/diarization_EN2002a.rttm"
with open(output_file, "w") as outfile:
    for fname in sorted(glob.glob("/content/EN2002a_chunk_*.rttm")):
        with open(fname, "r") as infile:
            outfile.write(infile.read())

print(f"Merged RTTM saved to {output_file}")

!head -n 5 /content/diarization_EN2002a.rttm

!ls -lh /content/diarization_EN2002a.rttm
!wc -l /content/diarization_EN2002a.rttm

!ls -lh /content/EN2002a_chunk_*.rttm
!head -n 5 /content/EN2002a_chunk_0.rttm

import os
import glob

output_file = "/content/diarization_EN2002a.rttm"
chunk_files = sorted(glob.glob("/content/**/EN2002a_chunk_*.rttm", recursive=True))

if not chunk_files:
    raise FileNotFoundError("No EN2002a_chunk_*.rttm files found. Check your folder paths!")

with open(output_file, "w") as outfile:
    for f in chunk_files:
        with open(f, "r") as infile:
            lines = [line.strip() for line in infile if line.strip()]
            if lines:
                for line in lines:
                    # Replace chunk IDs with single file ID
                    fixed_line = line.replace("_chunk_", "_")
                    outfile.write(fixed_line + "\n")
            else:
                print(f"Skipping empty RTTM: {f}")

print(f"Merged diarization RTTM saved at: {output_file}")
!head -n 10 {output_file}

input_file = "/content/diarization_EN2002a.rttm"
output_file = "/content/diarization_EN2002a_fixed.rttm"

with open(input_file, "r") as infile, open(output_file, "w") as outfile:
    for line in infile:
        fixed_line = line.replace("temp_0", "EN2002a")
        outfile.write(fixed_line)

print(f"Fixed diarization RTTM saved at: {output_file}")
!head -n 10 {output_file}

!head -n 5 /content/transcript_rttms/whisper_EN2002a.rttm
!head -n 5 /content/transcript_rttms/vosk_EN2002a.rttm

!find /content -type f -name "*EN2002a*.rttm"

!head -n 5 /content/whisper_EN2002a.rttm
!head -n 5 /content/vosk_EN2002a.rttm

!mkdir -p /content/transcript_rttms
!mv /content/whisper_EN2002a.rttm /content/transcript_rttms/
!mv /content/vosk_EN2002a.rttm /content/transcript_rttms/

!python calculate_der.py \
    --ref /content/diarization_EN2002a_fixed.rttm \
    --hyp_whisper /content/transcript_rttms/whisper_EN2002a.rttm \
    --hyp_vosk /content/transcript_rttms/vosk_EN2002a.rttm

!pip install pyannote.metrics

from pyannote.metrics.diarization import DiarizationErrorRate
from pyannote.core import Annotation, Segment

def load_rttm(path):
    ann = Annotation()
    with open(path, 'r') as f:
        for line in f:
            if not line.strip():
                continue
            parts = line.strip().split()
            start = float(parts[3])
            dur = float(parts[4])
            spk = parts[7]
            # Use Segment object instead of tuple
            ann[Segment(start, start + dur)] = spk
    return ann

# Load reference diarization (ground truth or fixed RTTM)
ref = load_rttm("/content/diarization_EN2002a_fixed.rttm")

# Load hypotheses
whisper = load_rttm("/content/transcript_rttms/whisper_EN2002a.rttm")
vosk = load_rttm("/content/transcript_rttms/vosk_EN2002a.rttm")

metric = DiarizationErrorRate()
print("DER vs Whisper:", metric(ref, whisper))
print("DER vs Vosk:", metric(ref, vosk))

from pyannote.core import Timeline, Segment
from pyannote.database.util import load_rttm  # Corrected import path
from pyannote.metrics.diarization import DiarizationErrorRate

# --- Load RTTM files ---
ref = load_rttm("/content/diarization_EN2002a_fixed.rttm")["EN2002a"]
whisper = load_rttm("/content/transcript_rttms/whisper_EN2002a.rttm")["EN2002a"]
vosk = load_rttm("/content/transcript_rttms/vosk_EN2002a.rttm")["EN2002a"]

# --- Create evaluation time window (UEM = reference extent) ---
ref_timeline = ref.get_timeline()
start_time = ref_timeline.extent().start
end_time = ref_timeline.extent().end
uem = Timeline(segments=[Segment(start_time, end_time)])

# --- Initialize metric ---
metric = DiarizationErrorRate()

# --- Evaluate DER ---
der_whisper = metric(ref, whisper, uem=uem)
der_vosk = metric(ref, vosk, uem=uem)

print("DER vs Whisper:", der_whisper)
print("DER vs Vosk:", der_vosk)

from tabulate import tabulate

# Put your results in a list of lists
results = [
    ["EN2002a", 0.678, 0.489]
]

headers = ["Recording", "DER Whisper", "DER Vosk"]
print(tabulate(results, headers=headers, floatfmt=".3f", tablefmt="github"))

import pandas as pd

df = pd.DataFrame(results, columns=["Recording", "DER Whisper", "DER Vosk"])
df.to_csv("/content/der_results.csv", index=False)
print("Results saved to /content/der_results.csv")
df